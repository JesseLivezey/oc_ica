{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K40c (CNMeM is enabled with initial size: 20.0% of memory, cuDNN 4007)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'oc_ica.analysis' from '/home/jesse/Development/oc_ica/oc_ica/analysis.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patheffects as pe\n",
    "import numpy as np\n",
    "import cPickle, h5py, os, glob\n",
    "\n",
    "from oc_ica import analysis, styles, plotting\n",
    "reload(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_folder = '/home/jesse/Development/results/oc_ica/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kkkkkkkkkkkkkk 2\n",
      "kkkkkkkkkkkkkk 2\n",
      "kkkkkkkkkkkkkk 4\n",
      "kkkkkkkkkkkkkk 4\n",
      "kkkkkkkkkkkkkk 6\n",
      "kkkkkkkkkkkkkk 6\n",
      "kkkkkkkkkkkkkk 8\n",
      "kkkkkkkkkkkkkk 8\n",
      "kkkkkkkkkkkkkk 10\n",
      "kkkkkkkkkkkkkk 10\n",
      "kkkkkkkkkkkkkk 12\n",
      "kkkkkkkkkkkkkk 12\n",
      "kkkkkkkkkkkkkk 14\n",
      "kkkkkkkkkkkkkk 14\n",
      "kkkkkkkkkkkkkk 16\n",
      "kkkkkkkkkkkkkk 16\n"
     ]
    }
   ],
   "source": [
    "reload(analysis)\n",
    "n_mixtures = 32\n",
    "OCs = ['0.75', '1.0', '1.5', '2.0', '2.25', '2.5', '2.75', '3.0', '3.5', '4.0']\n",
    "#OCs = ['1.0', '1.5']\n",
    "k = 12\n",
    "priors = ['COHERENCE_SOFT', 'COHERENCE', 'INIT']\n",
    "keep_max = False\n",
    "\n",
    "for OC in OCs:\n",
    "    analysis.comparison_analysis_postprocess(base_folder, n_mixtures, OC, k, priors, keep_max, overwrite=True)\n",
    "    \n",
    "ks = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "#ks = [2, 4]\n",
    "OC = '2.0'\n",
    "for k in ks:\n",
    "    print 'kkkkkkkkkkkkkk', k\n",
    "    analysis.comparison_analysis_postprocess(base_folder, n_mixtures, OC, k, priors, keep_max, overwrite=True)\n",
    "    print 'kkkkkkkkkkkkkk', k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior: COHERENCE_SOFT\n",
      "0 1.0 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 1.0 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 1.0 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 1.0 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 1.0 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 1.0 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 1.0 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 1.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 1.5 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.25 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.5 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.75 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 3.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 0 0 2 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 1 1 4 (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 2 2 COULOMB (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 3 3 COULOMB_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 4 4 RANDOM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 5 5 RANDOM_F (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 6 7 SM (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 3.5 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "0 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "1 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "2 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "3 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "4 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "5 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "6 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n",
      "7 2.0 7 6 SC (3, 8, 17, 45, 2) (3, 8, 17, 10, 2)\n"
     ]
    }
   ],
   "source": [
    "reload(analysis)\n",
    "OC = '2.0'\n",
    "k = 12\n",
    "\n",
    "results, null_results, lambdas = analysis.comparison_analysis_postprocess(base_folder,\n",
    "                                                                          n_mixtures, OC, k, priors, keep_max)\n",
    "\n",
    "\n",
    "OCs = ['0.75', '1.0', '1.5', '2.0', '2.25', '2.5', '2.75', '3.0', '3.5', '4.0']\n",
    "keep_OCs = ['1.0', '1.5', '2.0', '2.25', '2.5', '2.75', '3.0', '3.5']\n",
    "\n",
    "#OCs = ['1.0', '1.5']\n",
    "#keep_OCs = ['1.0', '1.5']\n",
    "k = 12\n",
    "\n",
    "models = ['2', '4', 'COULOMB', 'COULOMB_F', 'RANDOM', 'RANDOM_F', 'SC', 'SM']\n",
    "keep_models = ['2', '4', 'COULOMB', 'COULOMB_F', 'RANDOM', 'RANDOM_F', 'SM', 'SC']\n",
    "\n",
    "ks = [2, 4, 6, 8, 10, 12, 14, 16]\n",
    "#ks = [2, 4]\n",
    "\n",
    "labelpad = -0\n",
    "\n",
    "n_prior = 0\n",
    "f = plt.figure(figsize=(8, 5))\n",
    "ae = plt.subplot2grid((2, 12), (0, 0), colspan=4)\n",
    "am = plt.subplot2grid((2, 12), (0, 4), colspan=4)\n",
    "ap = plt.subplot2grid((2, 12), (0, 8), colspan=4)\n",
    "ax1 = plt.subplot2grid((2, 12), (1, 0), colspan=5)\n",
    "ax2 = plt.subplot2grid((2, 12), (1, 5), colspan=5)\n",
    "\n",
    "p = priors[n_prior]\n",
    "print('prior: {}'.format(p))\n",
    "ii = n_prior\n",
    "for jj, m in enumerate(keep_models):\n",
    "    jjp = models.index(m)\n",
    "    if m in styles.models:\n",
    "        fmt = styles.line_styles[m]\n",
    "\n",
    "        color = styles.colors[m]\n",
    "        label = styles.labels[m]\n",
    "\n",
    "        if m == 'SM':\n",
    "            delta = np.tile(np.nanmean(results[ii, jjp, 0, :, 0]), lambdas.size)\n",
    "            mma = np.tile(np.nanmean(results[ii, jjp, 0, :, 1]), lambdas.size)\n",
    "            null_delta = np.tile(np.nanmean(null_results[ii, jjp, 0, :, 0]), lambdas.size)\n",
    "            null_mma = np.tile(np.nanmean(null_results[ii, jjp, 0, :, 1]), lambdas.size)\n",
    "        else:\n",
    "            delta = np.nanmean(results[ii, jjp, :, :, 0], axis=1)\n",
    "            mma = np.nanmean(results[ii, jjp, :, :, 1], axis=1)\n",
    "            null_delta = np.nanmean(null_results[ii, jjp, :, :, 0], axis=1)\n",
    "            null_mma = np.nanmean(null_results[ii, jjp, :, :, 1], axis=1)\n",
    "        ae.semilogx(lambdas, delta, fmt, label=label, c=color, lw=2,\n",
    "                    path_effects=[pe.Stroke(linewidth=3, foreground='k'), pe.Normal()])\n",
    "        \n",
    "        ae.minorticks_off()\n",
    "        am.semilogx(lambdas, mma, fmt, label=label, c=color, lw=2,\n",
    "                    path_effects=[pe.Stroke(linewidth=3, foreground='k'), pe.Normal()])\n",
    "        \n",
    "        am.minorticks_off()\n",
    "        ap.semilogx(lambdas, .5*(delta/null_delta + mma/null_mma), fmt, label=label, c=color, lw=2,\n",
    "                    path_effects=[pe.Stroke(linewidth=3, foreground='k'), pe.Normal()])\n",
    "        if m != 'SM':\n",
    "            ae.semilogx(lambdas, delta, '.', c=color, ms=10, markeredgecolor='k')\n",
    "            am.semilogx(lambdas, mma, '.', c=color, ms=10, markeredgecolor='k')\n",
    "            ap.semilogx(lambdas, .5*(delta/null_delta + mma/null_mma), '.', c=color,\n",
    "                        ms=10, markeredgecolor='k')\n",
    "        \n",
    "        ap.minorticks_off()\n",
    "    \n",
    "#ae.legend(loc='best', ncol=2, prop={'size': 8}, frameon=False)\n",
    "#ae.set_title(p)\n",
    "ae.set_ylabel(r'$\\Delta P$', labelpad=labelpad, fontsize=12)\n",
    "ae.set_ylim([0, 50])\n",
    "#am.set_title(p)\n",
    "am.set_ylabel(r'median($p_{\\mathrm{min}}$)', labelpad=labelpad, fontsize=12)\n",
    "am.set_ylim([0, 65])\n",
    "#ap.set_title(p)\n",
    "ap.set_ylabel('Normalized Mean', labelpad=labelpad, fontsize=12)\n",
    "ap.set_ylim([0, 1.1])\n",
    "    \n",
    "ae.set_xlabel(r'$\\lambda$', labelpad=labelpad, fontsize=12)\n",
    "am.set_xlabel(r'$\\lambda$', labelpad=labelpad, fontsize=12)\n",
    "ap.set_xlabel(r'$\\lambda$', labelpad=labelpad, fontsize=12)\n",
    "ae.minorticks_off()\n",
    "am.minorticks_off()\n",
    "ap.minorticks_off()\n",
    "\n",
    "x = np.array([float(oc) for oc in keep_OCs])\n",
    "y = np.zeros((len(keep_models), x.size))\n",
    "y_std = np.zeros_like(y)\n",
    "for ii, OC in enumerate(keep_OCs):\n",
    "    iik = OCs.index(OC)\n",
    "    n_sources = int(n_mixtures * float(OC))\n",
    "    results, null_results, lambdas = analysis.comparison_analysis_postprocess(base_folder,\n",
    "                                                                          n_mixtures, OC, k, priors, keep_max)\n",
    "    for kk, m in enumerate(keep_models):\n",
    "        kkp = models.index(m)\n",
    "        print ii, OC, kk, kkp, m, null_results.shape, results.shape\n",
    "        if m == 'SM':\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp, 0], axis=0, keepdims=True)\n",
    "            r = results[n_prior, kkp, 0] / mean_null\n",
    "            pos = np.nanmean(r, axis=0).sum()\n",
    "            std = np.nanstd(r.sum(axis=-1))\n",
    "        else:\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp], axis=1, keepdims=True)\n",
    "            r = results[n_prior, kkp] / mean_null\n",
    "            r_mean = np.nanmean(r, axis=1).sum(axis=1)\n",
    "            r_min_idx = r_mean.argmin()\n",
    "            pos = np.nanmean(r[r_min_idx], axis=0).sum()\n",
    "            std = np.nanstd(r[r_min_idx].sum(axis=-1))\n",
    "        y[kk, ii] = pos\n",
    "        y_std[kk, ii] = std\n",
    "\n",
    "for ym, y_stdm, m in zip(y, y_std, keep_models):\n",
    "    fmt = styles.line_styles[m]\n",
    "    color = styles.colors[m]\n",
    "    label = styles.labels[m]\n",
    "    #ax1.errorbar(x, ym/2., yerr=y_stdm/2., fmt=fmt, color=color, label=label, lw=2,\n",
    "    #             path_effects=[pe.Stroke(linewidth=3, foreground='k'), pe.Normal()])\n",
    "    ax1.errorbar(x, ym/2., yerr=y_stdm/np.sqrt(10), fmt=fmt, color=color, label=label, lw=2,\n",
    "             path_effects=[pe.Stroke(linewidth=3, foreground='k'), pe.Normal()])\n",
    "ax1.set_xticks(np.linspace(1, 4, 4))\n",
    "ax1.set_yticks(np.linspace(0, 2, 3))\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.set_xlim(.9, 3.6)\n",
    "ax1.set_xlabel('Overcompleteness', labelpad=labelpad, fontsize=12)\n",
    "ax1.set_ylabel('Normalized Mean', labelpad=labelpad, fontsize=12)\n",
    "\n",
    "\n",
    "OC=2.\n",
    "x = np.array(ks)\n",
    "y = np.zeros((len(keep_models), x.size))\n",
    "y_std = np.zeros_like(y)\n",
    "for ii, k in enumerate(ks):\n",
    "    n_sources = int(n_mixtures * float(OC))\n",
    "    print ii, OC, kk, kkp, m, null_results.shape, results.shape\n",
    "    results, null_results, lambdas = analysis.comparison_analysis_postprocess(base_folder,\n",
    "                                                                          n_mixtures, OC, k, priors, keep_max)\n",
    "    for kk, m in enumerate(keep_models):\n",
    "        kkp = models.index(m)\n",
    "        if m == 'SM':\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp, 0], axis=0, keepdims=True)\n",
    "            r = results[n_prior, kkp, 0] / mean_null\n",
    "            pos = np.nanmean(r, axis=0).sum()\n",
    "            std = np.nanstd(r.sum(axis=-1))\n",
    "        else:\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp], axis=1, keepdims=True)\n",
    "            r = results[n_prior, kkp] / mean_null\n",
    "            r_mean = np.nanmean(r, axis=1).sum(axis=1)\n",
    "            r_min_idx = r_mean.argmin()\n",
    "            pos = np.nanmean(r[r_min_idx], axis=0).sum()\n",
    "            std = np.nanstd(r[r_min_idx].sum(axis=-1))\n",
    "        y[kk, ii] = pos\n",
    "        y_std[kk, ii] = std\n",
    "handles = []\n",
    "for ym, y_stdm, m in zip(y, y_std, keep_models):\n",
    "    fmt = styles.line_styles[m]\n",
    "    color = styles.colors[m]\n",
    "    label = styles.labels[m]\n",
    "    handles.append(ax2.errorbar(x, ym/2., yerr=y_stdm/np.sqrt(10), fmt=fmt, color=color, label=label, lw=2,\n",
    "                  path_effects=[pe.Stroke(linewidth=3, foreground='k'), pe.Normal()])[0])\n",
    "ax2.legend(loc='upper left', bbox_to_anchor=(.7, 1.15), frameon='False')\n",
    "ax2.set_xlim(1.5, 16.5)\n",
    "ax2.set_xticks(np.linspace(2, 16, 8))\n",
    "ax2.set_yticks(np.linspace(0, 1, 2))\n",
    "ax2.set_xlabel(r'$k$-sparseness', labelpad=labelpad, fontsize=12)\n",
    "ax2.set_ylabel('Normalized Mean', labelpad=labelpad, fontsize=12)\n",
    "\n",
    "f.text(.01, .95, 'a)', fontsize=14)\n",
    "f.text(.33, .95, 'b)', fontsize=14)\n",
    "f.text(.66, .95, 'c)', fontsize=14)\n",
    "f.text(.01, .47, 'd)', fontsize=14)\n",
    "f.text(.43, .47, 'e)', fontsize=14)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/jesse/Downloads/figure3.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_file = 'a_array-32_OC-2.0_priors-COHERENCE_INIT.h5'\n",
    "with h5py.File(os.path.join(base_folder, a_file), 'r') as f:\n",
    "    A_array = f['A_array'].value\n",
    "    A_priors = f['A_priors'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(plotting)\n",
    "plotting.plot_angles_1column(np.transpose(A_array, (0, 1, 3, 2)), 1, A_priors, plot_init=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 32, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 11, 17, 10, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 54.        ,  37.72133636],\n",
       "        [ 48.        ,  38.90277863],\n",
       "        [ 52.        ,  37.9727478 ],\n",
       "        [ 52.        ,  37.98392487],\n",
       "        [ 56.        ,  38.73665619],\n",
       "        [ 58.        ,  39.25117493],\n",
       "        [ 56.        ,  38.4540863 ],\n",
       "        [ 48.        ,  39.203125  ],\n",
       "        [ 64.        ,  39.57582092],\n",
       "        [ 52.        ,  38.31627655]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(202020)\n",
    "\n",
    "lambd = 1.0\n",
    "source_dim = 32\n",
    "n_samples = 10000\n",
    "k = 8\n",
    "\n",
    "S = rng.laplace(0, lambd, size=(source_dim, n_samples))\n",
    "S1 = np.copy(S)\n",
    "S2 = np.copy(S)\n",
    "\n",
    "for ii in range(n_samples):\n",
    "    idxs = np.argsort(abs(S[:,ii]))[:-k]\n",
    "    S1[idxs, ii] = 0.\n",
    "\n",
    "    idxs = rng.permutation(source_dim)[:source_dim-k]\n",
    "    S2[idxs, ii] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 5))\n",
    "ax1.hist(S1.ravel(), bins=1000)\n",
    "ax1.set_yscale('log')\n",
    "ax2.hist(S2.ravel(), bins=1000)\n",
    "ax2.set_yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        , -4.84437276],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       ..., \n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
