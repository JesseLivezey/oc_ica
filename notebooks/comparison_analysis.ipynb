{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'oc_ica.analysis' from '/home/jesse/Development/oc_ica/oc_ica/analysis.pyc'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cPickle, h5py, os, glob\n",
    "\n",
    "from oc_ica import analysis, styles, plotting\n",
    "reload(analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_folder = '/home/jesse/Development/results/oc_ica/'\n",
    "n_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 64 2.0 2\n",
      "a_array-32_OC-2.0_priors-COHERENCE_INIT.h5\n",
      "comparison_mixtures-32_sources-64_k-2_priors-COHERENCE_INIT\n",
      "9 ['2', '4', 'COHERENCE_SOFT', 'COULOMB', 'COULOMB_F', 'RANDOM', 'RANDOM_F', 'SC', 'SM']\n"
     ]
    }
   ],
   "source": [
    "n_mixtures = 32\n",
    "OC = '2.0'\n",
    "k = 2\n",
    "priors = ['COHERENCE', 'INIT']\n",
    "n_sources = int(n_mixtures * float(OC))\n",
    "print n_mixtures, n_sources, OC, k\n",
    "fit_folder = 'comparison_mixtures-{}_sources-{}_k-{}_priors-{}'.format(n_mixtures, n_sources, k, '_'.join(priors))\n",
    "a_file = 'a_array-{}_OC-{}_priors-{}.h5'.format(n_mixtures, OC, '_'.join(priors))\n",
    "print a_file\n",
    "print fit_folder\n",
    "fit_files = sorted(glob.glob(os.path.join(base_folder, fit_folder, 'comparison*.h5')))\n",
    "sc_fits = None\n",
    "models = [f.split('.')[-2].split('-')[-1] for f in fit_files]\n",
    "print len(models), models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(base_folder, a_file), 'r') as f:\n",
    "    A_array = f['A_array'].value\n",
    "    A_priors = f['A_priors'].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_colors = ['black', 'blue', 'red', 'green', 'purple', 'cyan']\n",
    "seq_ftms = ['-', ':', '-.']\n",
    "ver_ftms = ['-', '--']\n",
    "model_color = {}\n",
    "model_fmt = {}\n",
    "color_idx = 1\n",
    "int_idx = 0\n",
    "for model in models:\n",
    "    base_model = model.split('_')[0]\n",
    "    if base_model.isdigit():\n",
    "        model_color[model] = all_colors[0]\n",
    "        model_fmt[model] = seq_ftms[int_idx]\n",
    "        int_idx += 1\n",
    "    elif '_' in model:\n",
    "        if base_model in model_color.keys():\n",
    "            model_color[model] = model_color[base_model]\n",
    "            model_fmt[model] = ver_ftms[1]\n",
    "        else:\n",
    "            model_color[model] = all_colors[color_idx]\n",
    "            model_fmt[model] = ver_ftms[0]\n",
    "            color_idx += 1\n",
    "    else:\n",
    "        if model in [m.split('_')[0] for m in model_color.keys()]:\n",
    "            eqiv = [m for m in model_color.keys() if model == m.split('_')[0]][0]\n",
    "        else:\n",
    "            model_color[model] = all_colors[color_idx]\n",
    "            model_fmt[model] = ver_ftms[0]\n",
    "            color_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with h5py.File(os.path.join(base_folder, fit_folder, fit_files[0]), 'r') as f:\n",
    "    lambdas = f['lambdas'].value\n",
    "n_mixtures, n_sources = A_array.shape[2:]\n",
    "n_iter = A_array.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "W_fits = np.full((len(A_priors), len(models), lambdas.size, n_iter, n_sources, n_mixtures),\n",
    "                 np.nan, dtype='float32')\n",
    "results = np.full((len(A_priors), len(models), lambdas.size, n_iter, 2),\n",
    "                  np.nan, dtype='float32')\n",
    "null_results = np.full((len(A_priors), len(models), lambdas.size, (n_iter**2-n_iter)//2, 2),\n",
    "                  np.nan, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for ii, f_name in enumerate(fit_files):\n",
    "    with h5py.File(os.path.join(base_folder, fit_folder, f_name), 'r') as f:\n",
    "        W_fits[:, ii] = np.squeeze(f['W_fits'])[:, :, :n_iter]\n",
    "\n",
    "if sc_fits is not None:\n",
    "    loc = 0\n",
    "    for ii, f_name in enumerate(sc_fits):\n",
    "        with h5py.File(os.path.join(base_folder, fit_folder, f_name), 'r') as f:\n",
    "            n_lambdas = f['W_fits'].shape[2]\n",
    "            W_fits[:, -1, loc:loc+n_lambdas, :10] = np.squeeze(f['W_fits'])[:, :, :n_iter]\n",
    "            loc += n_lambdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(analysis)\n",
    "results_file = os.path.join(base_folder, fit_folder, 'results.h5')\n",
    "if False: #os.path.exists(results_file):\n",
    "    with h5py.File(results_file) as f:\n",
    "        results = f['results'].value\n",
    "else:\n",
    "    for ii, p in enumerate(A_priors):\n",
    "        for jj, m in enumerate(models):\n",
    "            for kk, l in enumerate(lambdas):\n",
    "                for ll in range(n_iter):\n",
    "                    try:\n",
    "                        A = A_array[ii, ll]\n",
    "                        W = W_fits[ii, jj, kk, ll]\n",
    "                        assert (not np.isnan(A.sum())) and (not np.isnan(W.sum()))\n",
    "                        results[ii, jj, kk, ll] = analysis.recovery_statistics_AW(A, W)\n",
    "                        #results[ii, jj, kk, ll] = [hd, pd, mod]\n",
    "                        #max_angles[ii, jj, kk, ll] = ma\n",
    "                        #other_angles[ii, jj, kk, ll] = oa\n",
    "                    except (ValueError, AssertionError):\n",
    "                        pass\n",
    "    with h5py.File(results_file, 'w') as f:\n",
    "        f.create_dataset('results', data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_file = os.path.join(base_folder, fit_folder, 'null_results.h5')\n",
    "if False: #os.path.exists(results_file):\n",
    "    with h5py.File(results_file) as f:\n",
    "        null_results = f['null_results'].value\n",
    "else:\n",
    "    for ii, p in enumerate(A_priors):\n",
    "        for jj, m in enumerate(models):\n",
    "            for kk, l in enumerate(lambdas):\n",
    "                loc = 0\n",
    "                for ll in range(n_iter):\n",
    "                    for mm in range(ll+1, n_iter):\n",
    "                        try:\n",
    "                            A = A_array[ii, ll]\n",
    "                            W = W_fits[ii, jj, kk, mm]\n",
    "                            assert (not np.isnan(A.sum())) and (not np.isnan(W.sum()))\n",
    "                            null_results[ii, jj, kk, loc] = analysis.recovery_statistics_AW(A, W)\n",
    "                            loc += 1\n",
    "                        except (ValueError, AssertionError):\n",
    "                            pass\n",
    "    with h5py.File(results_file, 'w') as f:\n",
    "        f.create_dataset('null_results', data=null_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Summary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prior: INIT\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-2_priors-COHERENCE_INIT/results.h5\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-2_priors-COHERENCE_INIT/null_results.h5\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-4_priors-COHERENCE_INIT/results.h5\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-4_priors-COHERENCE_INIT/null_results.h5\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-8_priors-COHERENCE_INIT/results.h5\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-8_priors-COHERENCE_INIT/null_results.h5\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-16_priors-COHERENCE_INIT/results.h5\n",
      "/home/jesse/Development/results/oc_ica/comparison_mixtures-32_sources-64_k-16_priors-COHERENCE_INIT/null_results.h5\n"
     ]
    }
   ],
   "source": [
    "n_mixtures = 32\n",
    "OCs = ['1.0', '1.5', '2.0', '2.05', '2.25', '2.5', '2.75', '3.0', '4.0', '8.0']\n",
    "keep_OCs = ['1.0', '1.5', '2.0', '2.25', '2.5', '2.75', '3.0', '4.0', '8.0']\n",
    "k = 2\n",
    "\n",
    "keep_models = ['2', '4', 'COHERENCE_SOFT', 'COULOMB', 'COULOMB_F', 'RANDOM', 'RANDOM_F', 'SC', 'SM']\n",
    "\n",
    "ks = [2, 4, 8, 16]\n",
    "\n",
    "labelpad = -3\n",
    "\n",
    "n_prior = 1\n",
    "f = plt.figure(figsize=(10, 8))\n",
    "ae = plt.subplot2grid((3, 3), (0, 0))\n",
    "am = plt.subplot2grid((3, 3), (0, 1))\n",
    "ap = plt.subplot2grid((3, 3), (0, 2))\n",
    "p = A_priors[n_prior]\n",
    "print('prior: {}'.format(p))\n",
    "ii = n_prior\n",
    "for jj, m in enumerate(keep_models):\n",
    "    jjp = models.index(m)\n",
    "    if m in styles.models:\n",
    "        fmt = styles.line_styles[m]\n",
    "\n",
    "        color = styles.colors[m]\n",
    "        label = styles.labels[m]\n",
    "\n",
    "        if m == 'SM':\n",
    "            delta = np.tile(np.nanmean(results[ii, jjp, 0, :, 0]), lambdas.size)\n",
    "            mma = np.tile(np.nanmean(results[ii, jjp, 0, :, 1]), lambdas.size)\n",
    "            null_delta = np.tile(np.nanmean(null_results[ii, jjp, 0, :, 0]), lambdas.size)\n",
    "            null_mma = np.tile(np.nanmean(null_results[ii, jjp, 0, :, 1]), lambdas.size)\n",
    "        else:\n",
    "            delta = np.nanmean(results[ii, jjp, :, :, 0], axis=1)\n",
    "            mma = np.nanmean(results[ii, jjp, :, :, 1], axis=1)\n",
    "            null_delta = np.nanmean(null_results[ii, jjp, :, :, 0], axis=1)\n",
    "            null_mma = np.nanmean(null_results[ii, jjp, :, :, 1], axis=1)\n",
    "\n",
    "        ae.semilogx(lambdas, delta, fmt, label=label, c=color)\n",
    "        ae.semilogx(lambdas, delta, '.', c=color)\n",
    "        ae.minorticks_off()\n",
    "        am.semilogx(lambdas, mma, fmt, label=label, c=color)\n",
    "        am.semilogx(lambdas, mma, '.', c=color)\n",
    "        am.minorticks_off()\n",
    "        ap.semilogx(lambdas, delta/null_delta + mma/null_mma, fmt, label=label, c=color)\n",
    "        ap.semilogx(lambdas, delta/null_delta + mma/null_mma, '.', c=color)\n",
    "        ap.minorticks_off()\n",
    "    \n",
    "#ae.legend(loc='best', ncol=2, prop={'size': 8}, frameon=False)\n",
    "#ae.set_title(p)\n",
    "ae.set_ylabel(r'$\\Delta P$', labelpad=labelpad, fontsize=12)\n",
    "ae.set_ylim([0, np.nanmax(results[...,0])])\n",
    "#am.set_title(p)\n",
    "am.set_ylabel(r'median($p_{\\mathrm{min}}$)', labelpad=labelpad, fontsize=12)\n",
    "am.set_ylim([0, 80])\n",
    "#ap.set_title(p)\n",
    "ap.set_ylabel('Normalized Sum', labelpad=labelpad, fontsize=12)\n",
    "ap.set_ylim([0, 2.5])\n",
    "    \n",
    "ae.set_xlabel(r'$\\lambda$', labelpad=labelpad, fontsize=12)\n",
    "am.set_xlabel(r'$\\lambda$', labelpad=labelpad, fontsize=12)\n",
    "ap.set_xlabel(r'$\\lambda$', labelpad=labelpad, fontsize=12)\n",
    "\n",
    "ax1 = plt.subplot2grid((3, 3), (1, 0), colspan=3)\n",
    "ax2 = plt.subplot2grid((3, 3), (2, 0), colspan=3)\n",
    "\n",
    "x = np.array([float(oc) for oc in keep_OCs])\n",
    "y = np.zeros((len(keep_models), x.size))\n",
    "y_std = np.zeros_like(y)\n",
    "for ii, OC in enumerate(keep_OCs):\n",
    "    iik = OCs.index(OC)\n",
    "    n_sources = int(n_mixtures * float(OC))\n",
    "    fit_folder = 'comparison_mixtures-{}_sources-{}_k-{}_priors-{}'.format(n_mixtures, n_sources, k, '_'.join(priors))\n",
    "    results_file = os.path.join(base_folder, fit_folder, 'results.h5')\n",
    "    null_results_file = os.path.join(base_folder, fit_folder, 'null_results.h5')\n",
    "    with h5py.File(results_file) as f:\n",
    "        results = f['results'].value\n",
    "    with h5py.File(null_results_file) as f:\n",
    "        null_results = f['null_results'].value\n",
    "    for kk, m in enumerate(keep_models):\n",
    "        kkp = models.index(m)\n",
    "        if m == 'SM':\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp, 0], axis=0, keepdims=True)\n",
    "            r = results[n_prior, kkp, 0] / mean_null\n",
    "            pos = np.nanmean(r, axis=0).sum()\n",
    "            std = np.nanstd(r.sum(axis=-1))\n",
    "        else:\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp], axis=1, keepdims=True)\n",
    "            r = results[n_prior, kkp] / mean_null\n",
    "            r_mean = np.nanmean(r, axis=1).sum(axis=1)\n",
    "            r_min_idx = r_mean.argmin()\n",
    "            pos = np.nanmean(r[r_min_idx], axis=0).sum()\n",
    "            std = np.nanstd(r[r_min_idx].sum(axis=-1))\n",
    "        y[kk, ii] = pos\n",
    "        y_std[kk, ii] = std\n",
    "\n",
    "for ym, y_stdm, m in zip(y, y_std, keep_models):\n",
    "    fmt = styles.line_styles[m]\n",
    "    color = styles.colors[m]\n",
    "    label = styles.labels[m]\n",
    "    ax1.errorbar(x, ym, yerr=y_stdm, fmt=fmt, color=color, label=label)\n",
    "ax1.set_ylim(0, 2)\n",
    "ax1.set_xlim(.75, 4.25)\n",
    "ax1.set_xticks(np.linspace(1, 4, 4))\n",
    "ax1.set_yticks(np.linspace(0, 2, 3))\n",
    "ax1.set_xlabel('Overcompleteness', labelpad=labelpad, fontsize=12)\n",
    "ax1.set_ylabel('Normalized Sum', labelpad=labelpad, fontsize=12)\n",
    "\n",
    "\n",
    "OC=2.\n",
    "x = np.array(ks)\n",
    "y = np.zeros((len(keep_models), x.size))\n",
    "y_std = np.zeros_like(y)\n",
    "for ii, k in enumerate(ks):\n",
    "    n_sources = int(n_mixtures * float(OC))\n",
    "    fit_folder = 'comparison_mixtures-{}_sources-{}_k-{}_priors-{}'.format(n_mixtures, n_sources, k, '_'.join(priors))\n",
    "    results_file = os.path.join(base_folder, fit_folder, 'results.h5')\n",
    "    null_results_file = os.path.join(base_folder, fit_folder, 'null_results.h5')\n",
    "    print results_file\n",
    "    with h5py.File(results_file) as f:\n",
    "        results = f['results'].value\n",
    "    print null_results_file\n",
    "    with h5py.File(null_results_file) as f:\n",
    "        null_results = f['null_results'].value\n",
    "    for kk, m in enumerate(keep_models):\n",
    "        kkp = models.index(m)\n",
    "        if m == 'SM':\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp, 0], axis=0, keepdims=True)\n",
    "            r = results[n_prior, kkp, 0] / mean_null\n",
    "            pos = np.nanmean(r, axis=0).sum()\n",
    "            std = np.nanstd(r.sum(axis=-1))\n",
    "        else:\n",
    "            mean_null = np.nanmean(null_results[n_prior, kkp], axis=1, keepdims=True)\n",
    "            r = results[n_prior, kkp] / mean_null\n",
    "            r_mean = np.nanmean(r, axis=1).sum(axis=1)\n",
    "            r_min_idx = r_mean.argmin()\n",
    "            pos = np.nanmean(r[r_min_idx], axis=0).sum()\n",
    "            std = np.nanstd(r[r_min_idx].sum(axis=-1))\n",
    "        y[kk, ii] = pos\n",
    "        y_std[kk, ii] = std\n",
    "\n",
    "for ym, y_stdm, m in zip(y, y_std, keep_models):\n",
    "    fmt = styles.line_styles[m]\n",
    "    color = styles.colors[m]\n",
    "    label = styles.labels[m]\n",
    "    ax2.errorbar(x, ym, yerr=y_stdm, fmt=fmt, color=color, label=label)\n",
    "ax2.legend(loc='best', ncol=2, frameon=False)\n",
    "ax2.set_xlim(1, 17)\n",
    "ax2.set_xticks(np.linspace(2, 16, 8))\n",
    "ax2.set_yticks(np.linspace(0, 2, 3))\n",
    "ax2.set_xlabel(r'$k$-sparseness', labelpad=labelpad, fontsize=12)\n",
    "ax2.set_ylabel('Normalized Sum', labelpad=labelpad, fontsize=12)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# A Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a_file = 'a_array-32_OC-2.0_priors-COHERENCE_INIT.h5'\n",
    "with h5py.File(os.path.join(base_folder, a_file), 'r') as f:\n",
    "    A_array = f['A_array'].value\n",
    "    A_priors = f['A_priors'].value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(plotting)\n",
    "plotting.plot_angles_1column(np.transpose(A_array, (0, 1, 3, 2)), 1, A_priors, plot_init=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 10, 32, 64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 11, 17, 10, 2)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 54.        ,  37.72133636],\n",
       "        [ 48.        ,  38.90277863],\n",
       "        [ 52.        ,  37.9727478 ],\n",
       "        [ 52.        ,  37.98392487],\n",
       "        [ 56.        ,  38.73665619],\n",
       "        [ 58.        ,  39.25117493],\n",
       "        [ 56.        ,  38.4540863 ],\n",
       "        [ 48.        ,  39.203125  ],\n",
       "        [ 64.        ,  39.57582092],\n",
       "        [ 52.        ,  38.31627655]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]],\n",
       "\n",
       "       [[         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan],\n",
       "        [         nan,          nan]]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
